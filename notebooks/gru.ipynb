{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import surprise\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from typing import Tuple\n",
    "from tqdm.auto import tqdm\n",
    "from pytorch_lightning.loggers import WandbLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movielens = surprise.Dataset.load_builtin('ml-100k', prompt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(movielens.raw_ratings, columns=[\"User\", \"Movie\", \"Rating\", \"Timestamp\"])\n",
    "df[\"User\"] = pd.to_numeric(df[\"User\"])\n",
    "df[\"Movie\"] = pd.to_numeric(df[\"Movie\"])\n",
    "df[\"Rating\"] = pd.to_numeric(df[\"Rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_mapping = {value: index for index, value in enumerate(df[\"User\"].unique())}\n",
    "inv_user_id_mapping = {v: k for k, v in user_id_mapping.items()}\n",
    "\n",
    "movie_id_mapping = {value: index for index, value in enumerate(df[\"Movie\"].unique())}\n",
    "inv_movie_id_mapping = {v: k for k, v in movie_id_mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"User\"] = df[\"User\"].apply(lambda x: user_id_mapping[x])\n",
    "df[\"Movie\"] = df[\"Movie\"].apply(lambda x: movie_id_mapping[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>User</th>\n      <th>Count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>402</th>\n      <td>402</td>\n      <td>737</td>\n    </tr>\n    <tr>\n      <th>650</th>\n      <td>650</td>\n      <td>685</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>58</td>\n      <td>636</td>\n    </tr>\n    <tr>\n      <th>442</th>\n      <td>442</td>\n      <td>540</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>37</td>\n      <td>518</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>475</th>\n      <td>475</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>135</th>\n      <td>135</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>813</th>\n      <td>813</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>903</th>\n      <td>903</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>232</th>\n      <td>232</td>\n      <td>20</td>\n    </tr>\n  </tbody>\n</table>\n<p>943 rows Ã— 2 columns</p>\n</div>",
      "text/plain": "     User  Count\n402   402    737\n650   650    685\n58     58    636\n442   442    540\n37     37    518\n..    ...    ...\n475   475     20\n135   135     20\n813   813     20\n903   903     20\n232   232     20\n\n[943 rows x 2 columns]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"User\")[[\"Movie\"]].count().reset_index().rename(columns={\"Movie\": \"Count\"}).sort_values(\"Count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLensTrainDataset(Dataset):\n",
    "    \"\"\"MovieLens PyTorch Dataset for Training\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe containing the movie ratings\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.users, self.items, self.ratings = self.get_dataset(df)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "  \n",
    "    def __getitem__(self, idx: int):\n",
    "        return self.users[idx], self.items[idx], self.ratings[idx]\n",
    "\n",
    "    def get_dataset(self, df: pd.DataFrame) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        return torch.tensor(df[\"User\"].values), torch.tensor(df[\"Movie\"].values), torch.tensor(df[\"Rating\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepRecommender(pl.LightningModule):\n",
    "    \"\"\" Deep Recommender\n",
    "    \n",
    "        Args:\n",
    "            num_users (int): Number of unique users\n",
    "            num_items (int): Number of unique items\n",
    "            ratings (pd.DataFrame): Dataframe containing the movie ratings for training\n",
    "            all_movieIds (list): List containing all movieIds (train + test)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_users: int, num_items: int):\n",
    "        super().__init__()\n",
    "        self.user_embedding = nn.Embedding(num_embeddings=num_users, embedding_dim=8)\n",
    "        self.item_embedding = nn.Embedding(num_embeddings=num_items, embedding_dim=8)\n",
    "        self.fc1 = nn.Linear(in_features=16, out_features=64)\n",
    "        self.fc2 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.output = nn.Linear(in_features=32, out_features=1)\n",
    "        \n",
    "    def forward(self, user_input, item_input):\n",
    "        user_embedded = self.user_embedding(user_input)\n",
    "        item_embedded = self.item_embedding(item_input)\n",
    "\n",
    "        vector = torch.cat([user_embedded, item_embedded], dim=-1)\n",
    "        vector = nn.ReLU()(self.fc1(vector))\n",
    "        vector = nn.ReLU()(self.fc2(vector))\n",
    "\n",
    "        res = self.output(vector)\n",
    "\n",
    "        return res\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        user_input, item_input, labels = batch\n",
    "        predicted_labels = self(user_input, item_input)\n",
    "        loss = nn.MSELoss()(predicted_labels, labels.view(-1, 1).float())\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        user_input, item_input, labels = batch\n",
    "        predicted_labels = self(user_input, item_input)\n",
    "        loss = nn.MSELoss()(predicted_labels, labels.view(-1, 1).float())\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "\n",
      "  | Name           | Type      | Params\n",
      "---------------------------------------------\n",
      "0 | user_embedding | Embedding | 7.5 K \n",
      "1 | item_embedding | Embedding | 13.5 K\n",
      "2 | fc1            | Linear    | 1.1 K \n",
      "3 | fc2            | Linear    | 2.1 K \n",
      "4 | output         | Linear    | 33    \n",
      "---------------------------------------------\n",
      "24.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.2 K    Total params\n",
      "0.097     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4d0b908745147b3aba7e6b4c99de375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Validation sanity check: 0it [00:00, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9f525b6b2c54660b5e10299cd5c4f5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Training: 0it [00:00, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7809f96e203540c49a394cfede6ca4f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Validating: 0it [00:00, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1bcddb4b99d49fab9ce10db336d272d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Validating: 0it [00:00, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a6ef61359ba40d497cbab58b9a5af1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Validating: 0it [00:00, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_users = len(df[\"User\"].unique())\n",
    "num_movie = len(df[\"Movie\"].unique())\n",
    "\n",
    "recommender = DeepRecommender(num_users, num_movie)\n",
    "dataset = MovieLensTrainDataset(df)\n",
    "train_size = int(0.8 * len(df))\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, len(df) - train_size])\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=512, num_workers=0)\n",
    "\n",
    "test_loader = DataLoader(test_dataset,\n",
    "batch_size=512, num_workers=0)\n",
    "\n",
    "\n",
    "wandb_logger = WandbLogger()\n",
    "\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=3, logger=wandb_logger)\n",
    "trainer.fit(model=recommender, train_dataloader=train_loader, val_dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8  ('venv': venv)",
   "metadata": {
    "interpreter": {
     "hash": "cba70d05618ea7eb51a384ca103fdfbcbf0b78c16183c0fc8e62f02054b28d86"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}